<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Robotics on Sebastian Brunner</title>
    <link>https://sebastian-brunner.github.io/tags/robotics/</link>
    <description>Recent content in Robotics on Sebastian Brunner</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://sebastian-brunner.github.io/tags/robotics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Robot Simulation</title>
      <link>https://sebastian-brunner.github.io/project/robot_simulation/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/project/robot_simulation/</guid>
      <description>&lt;p&gt;Our &lt;a href=&#34;https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-11409&#34; target=&#34;_blank&#34;&gt;AIMM&lt;/a&gt; robot was simulated using the Gazebo Framework and the ROS middleware. The robot&amp;rsquo;s 12 DOFs were simulated using Gazebo&amp;rsquo;s controller suite. On top of that, path planning, object detection, navigation, world model, and task control (RAFCON) modules were integrated. The simulation was used for industrial and domestic service scenarios (among others for the &lt;a href=&#34;https://ease-crc.org/&#34; target=&#34;_blank&#34;&gt;EASE&lt;/a&gt; project).&lt;/p&gt;

&lt;p&gt;My responsibilities: Full Stack Component Integration, Controller Configuration, Autonomous Task Control, Task Execution Logging and Profiling, Semantic World Modeling&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Industrial Mobile Manipulation</title>
      <link>https://sebastian-brunner.github.io/project/industrial_mobile_robotics/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/project/industrial_mobile_robotics/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-11409&#34; target=&#34;_blank&#34;&gt;AIMM&lt;/a&gt; robot is an industrial mobile manipulator able to autonomously perceive and manipulate its environment. It was used for various scenarios (especially pre-assembly and logistics) in multiple projects and demos: &lt;a href=&#34;https://factory-of-the-future.dlr.de/&#34; target=&#34;_blank&#34;&gt;FoF&lt;/a&gt;, &lt;a href=&#34;http://www.euroc-project.eu/&#34; target=&#34;_blank&#34;&gt;EuRoC&lt;/a&gt;, &lt;a href=&#34;https://messe-muenchen.de/en/technical/events/automatica-2018.php&#34; target=&#34;_blank&#34;&gt;Automatica 2018&lt;/a&gt;, &lt;a href=&#34;http://www.tapas-project.eu/&#34; target=&#34;_blank&#34;&gt;TAPAS&lt;/a&gt; and &lt;a href=&#34;https://messe-muenchen.de/en/technical/events/automatica-2016.php&#34; target=&#34;_blank&#34;&gt;Automatica 2016&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I am a core developer of AIMM&amp;rsquo;s software stack. My main responsibilities are creating software for autonomous task control and belief state modeling. We put a high effort in the system architecture of AIMM, as it is a complex, mobile robot with 13 DOFs (including an impedance controlled LWR 4+), four cameras systems (able to produce depth information using &lt;a href=&#34;https://core.ac.uk/download/pdf/11134866.pdf&#34; target=&#34;_blank&#34;&gt;SGM&lt;/a&gt;) and laser scanners. It features six computers: One for low-level realtime control, one for navigation, one for object detection and scene reconstruction, one for path planning, one for data logging and processing and one for high level autonomy. On top of the multitude of software models we employ four different middlewares: &amp;lsquo;links and nodes&amp;rsquo; for realtime control, &amp;lsquo;sensornet&amp;rsquo; for high bandwidth sensor data, &amp;lsquo;ROS&amp;rsquo; for third party library integration and data visualization, and Kuka&amp;rsquo;s Sunrise middleware. We use continuous integration to develop and release new software. Furthermore, we employ a powerful release and dependency management toolchain to track and deploy consistent software versions to AIMM.&lt;/p&gt;

&lt;p&gt;My responsibilities: Autonomous Task Control, System Architecture, Task Execution Logging and Profiling, Semantic World Modeling&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Design, Execution, and Post-Mortem Analysis of Prolonged Autonomous Robot Operations</title>
      <link>https://sebastian-brunner.github.io/publication/ral1/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/publication/ral1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards Autonomous Planetary Exploration: The Lightweight Rover Unit (LRU), its Success in the SpaceBotCamp Challenge, and Beyond</title>
      <link>https://sebastian-brunner.github.io/publication/jint/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/publication/jint/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Robex</title>
      <link>https://sebastian-brunner.github.io/project/robex/</link>
      <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/project/robex/</guid>
      <description>&lt;p&gt;For the Demonstration Mission Space a dedicated scenario was chosen by the ROBEX lunar scientists. The scenario describes the installation of an active seismic network (ASN) on the Moon’s surface. The main focus is the measurement of the internal structure and the composition of the upper layer, the lunar regolith. Other questions are the existence and composition of a central core of the Moon and if there is any seismic activity. The seismometers are planned to be transported by a rover and put down on surface by means of a robotic arm.&lt;/p&gt;

&lt;p&gt;The analogue mission on the Mt. Etna basically consisted of two individual experiments: First, our rover mapped the lander site, deployed the seismic instrument, waited until one measurement cycle was done, took it up again and repeated the measurement on several points of interest. In the second experiment, the rover had to set up a seismic network consisting of four instruments that had to be arranged at three corner points and the center point of an equilateral triangle of about 100 m. Both scenarios required the robot to be equipped with highly robust navigation, perception and manipulation capabilities in order to place the instruments carefully and precisely onto the ground. Our robot was able to perform these tasks fully autonomously.&lt;/p&gt;

&lt;p&gt;My responsibilities: Autonomous Task Control, System Architecture, Task Execution Logging and Profiling, Semantic World Modeling&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robex</title>
      <link>https://sebastian-brunner.github.io/project/robex/</link>
      <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/project/robex/</guid>
      <description>&lt;p&gt;For the Demonstration Mission Space a dedicated scenario was chosen by the ROBEX lunar scientists. The scenario describes the installation of an active seismic network (ASN) on the Moon’s surface. The main focus is the measurement of the internal structure and the composition of the upper layer, the lunar regolith. Other questions are the existence and composition of a central core of the Moon and if there is any seismic activity. The seismometers are planned to be transported by a rover and put down on surface by means of a robotic arm.&lt;/p&gt;

&lt;p&gt;The analogue mission on the Mt. Etna basically consisted of two individual experiments: First, our rover mapped the lander site, deployed the seismic instrument, waited until one measurement cycle was done, took it up again and repeated the measurement on several points of interest. In the second experiment, the rover had to set up a seismic network consisting of four instruments that had to be arranged at three corner points and the center point of an equilateral triangle of about 100 m. Both scenarios required the robot to be equipped with highly robust navigation, perception and manipulation capabilities in order to place the instruments carefully and precisely onto the ground. Our robot was able to perform these tasks fully autonomously.&lt;/p&gt;

&lt;p&gt;My responsibilities: Autonomous Task Control, System Architecture, Task Execution Logging and Profiling, Semantic World Modeling&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RAFCON: A Graphical Tool for Engineering Complex, Robotic Tasks</title>
      <link>https://sebastian-brunner.github.io/publication/rafcon_iros/</link>
      <pubDate>Sat, 01 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/publication/rafcon_iros/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SpacebotCamp</title>
      <link>https://sebastian-brunner.github.io/project/spacebotcamp/</link>
      <pubDate>Sun, 13 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/project/spacebotcamp/</guid>
      <description>&lt;p&gt;In the SpacebotCamp, our mobile robotic system had to explore an unknwon area, find two objects and bring them to a third object for assembly. All tasks had to be done with a high level of autonomy since communication was delayed by 2 seconds and sending commands was limited to only a few occasions. The whole task had to be done in 60 minutes.&lt;/p&gt;

&lt;p&gt;Our team, RMexplores!, was the only team that fulfilled all tasks within the given specification. This was accomplished in half of the time!&lt;/p&gt;

&lt;p&gt;My responsibilities: Autonomous Task Control, System Architecture&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robocup</title>
      <link>https://sebastian-brunner.github.io/project/robocup/</link>
      <pubDate>Tue, 01 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/project/robocup/</guid>
      <description>&lt;p&gt;The Logistics League of the Robocup was set up in 2010 as a demonstration league for industrial applications and is sponsored by Festo since then. In 2012 the league got promoted to an approved major league of the RoboCup with continuously growing importance. The Logistics League enables scientific work for solving logistical problems inside a dynamic production environment with multiple self-organizing autonomous mobile robots. The robots are currently based on the robot platform Robotino from Festo, but can be modified individually in terms of hardware. In order to provide a high rate of product deliveries in due time, the teams have to achieve an efficient, precise and flexible material and information flow within the production hall. From 2014 on both competing teams operate within the same production environment at the same time, which also requires dynamic collision avoidance and increased spatial coordination complexity. This league offers an interdisciplinary approach in the fields of Mechatronics, Computer Science and Logistics in order to deal with all the challenges and requirements further described in the Logistics League Rulebook, including dynamic production plans, out-of-order machines, recycling, changing delivery gates and a random machine distribution.&lt;/p&gt;

&lt;p&gt;My team, the Bavarian Bending Units (former also TUM&amp;rsquo;s Bending Units), won the world championship three times in a row in the RoboCup Logistics League at RoboCup 2011 in Istanbul, at RoboCup 2012 in Mexico City, as well as at RoboCup 2013 in Eindhoven, Netherlands. In 2014, at RoboCup 2014 in João Pessoa, Brazil, we became vice world champion in an exciting and attractive final game against the team Carologistics from Aachen.&lt;/p&gt;

&lt;p&gt;My responsibilities: Perception, Navigation, ROS Infrastructure, Robot Communication&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
