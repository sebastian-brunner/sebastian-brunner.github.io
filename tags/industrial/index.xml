<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Industrial on Sebastian Brunner</title>
    <link>https://sebastian-brunner.github.io/tags/industrial/</link>
    <description>Recent content in Industrial on Sebastian Brunner</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://sebastian-brunner.github.io/tags/industrial/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Robot Simulation</title>
      <link>https://sebastian-brunner.github.io/project/robot_simulation/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/project/robot_simulation/</guid>
      <description>&lt;p&gt;Our &lt;a href=&#34;https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-11409&#34;&gt;AIMM&lt;/a&gt; robot was simulated using the Gazebo Framework and the ROS middleware. The robot&amp;rsquo;s 12 DOFs were simulated using Gazebo&amp;rsquo;s controller suite. On top of that, path planning, object detection, navigation, world model, and task control (RAFCON) modules were integrated. The simulation was used for industrial and domestic service scenarios (among others for the &lt;a href=&#34;https://ease-crc.org/&#34;&gt;EASE&lt;/a&gt; project).&lt;/p&gt;
&lt;p&gt;My responsibilities: Full Stack Component Integration, Controller Configuration, Autonomous Task Control, Task Execution Logging and Profiling, Semantic World Modeling&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Industrial Mobile Manipulation</title>
      <link>https://sebastian-brunner.github.io/project/industrial_mobile_robotics/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://sebastian-brunner.github.io/project/industrial_mobile_robotics/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-11409&#34;&gt;AIMM&lt;/a&gt; robot is an industrial mobile manipulator able to autonomously perceive and manipulate its environment. It was used for various scenarios (especially pre-assembly and logistics) in multiple projects and demos: &lt;a href=&#34;https://factory-of-the-future.dlr.de/&#34;&gt;FoF&lt;/a&gt;, &lt;a href=&#34;http://www.euroc-project.eu/&#34;&gt;EuRoC&lt;/a&gt;, &lt;a href=&#34;https://messe-muenchen.de/en/technical/events/automatica-2018.php&#34;&gt;Automatica 2018&lt;/a&gt;, &lt;a href=&#34;http://www.tapas-project.eu/&#34;&gt;TAPAS&lt;/a&gt; and &lt;a href=&#34;https://messe-muenchen.de/en/technical/events/automatica-2016.php&#34;&gt;Automatica 2016&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am a core developer of AIMM&amp;rsquo;s software stack. My main responsibilities are creating software for autonomous task control and belief state modeling. We put a high effort in the system architecture of AIMM, as it is a complex, mobile robot with 13 DOFs (including an impedance controlled LWR 4+), four cameras systems (able to produce depth information using &lt;a href=&#34;https://core.ac.uk/download/pdf/11134866.pdf&#34;&gt;SGM&lt;/a&gt;) and laser scanners. It features six computers: One for low-level realtime control, one for navigation, one for object detection and scene reconstruction, one for path planning, one for data logging and processing and one for high level autonomy. On top of the multitude of software models we employ four different middlewares: &amp;lsquo;links and nodes&amp;rsquo; for realtime control, &amp;lsquo;sensornet&amp;rsquo; for high bandwidth sensor data, &amp;lsquo;ROS&amp;rsquo; for third party library integration and data visualization, and Kuka&amp;rsquo;s Sunrise middleware. We use continuous integration to develop and release new software. Furthermore, we employ a powerful release and dependency management toolchain to track and deploy consistent software versions to AIMM.&lt;/p&gt;
&lt;p&gt;My responsibilities: Autonomous Task Control, System Architecture, Task Execution Logging and Profiling, Semantic World Modeling&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
